web_extractor:
  user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
  min_line_length: 30

qa_generator:
  model_name: "gemini-2.5-flash-preview-04-17"
  num_default_pairs: 500

fine_tuner:
  base_model: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  training:
    num_train_epochs: 10.0
    per_device_train_batch_size: 4
    learning_rate: 2.0e-4
    weight_decay: 0.01
    max_grad_norm: 0.3
    warmup_ratio: 0.03
    lr_scheduler_type: "cosine"
    dataloader_pin_memory: false
  lora:
    r: 8
    lora_alpha: 32
    lora_dropout: 0.1
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    bias: "none"
    inference_mode: false
    task_type: "CAUSAL_LM"